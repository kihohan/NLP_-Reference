# Contents

### - Sequence Bucketing (Dynamic Padding, Bucketing)
https://www.altoros.com/blog/the-magic-behind-google-translate-sequence-to-sequence-models-and-tensorflow/

### - Pytorch PackedSequence
https://simonjisu.github.io/nlp/2018/07/05/packedsequence.html

### - Question And Answer
https://medium.com/analytics-vidhya/bert-using-hugging-face-for-sentiment-extraction-with-pytorch-2477980e7976

https://mccormickml.com/2020/03/10/question-answering-with-a-fine-tuned-BERT/

### - Multi-gpu
https://medium.com/daangn/pytorch-multi-gpu-%ED%95%99%EC%8A%B5-%EC%A0%9C%EB%8C%80%EB%A1%9C-%ED%95%98%EA%B8%B0-27270617936b

### - Multi-gpu for keras
https://3months.tistory.com/211

### - Multi-Data-Type Classification for multi_input (keras)

https://stackabuse.com/python-for-nlp-creating-multi-data-type-classification-models-with-keras/

### - Bert binary Text Classification (tensorflow_hub) 

https://www.kaggle.com/ratan123/in-depth-guide-to-google-s-bert

https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub

### - Transformer Structure

https://blog.pingpong.us/transformer-review/

### - Multi Text Classification Example

https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568

### - TextRank For Keyword Extraction

https://towardsdatascience.com/textrank-for-keyword-extraction-by-python-c0bae21bcec0

### - 한글 자음/모음 분해

https://frhyme.github.io/python/python_korean_englished/

### - Illustrated: Self-Attention

https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a

https://colab.research.google.com/drive/1rPk3ohrmVclqhH7uQ7qys4oznDdAhpzF?fbclid=IwAR2_D4c-A7H-9v0zijkBd4jEoLhKbEtCqVCAZIaplRtGCLtjk1oodedzh38

### - Sentencepiece Colab

https://colab.research.google.com/github/google/sentencepiece/blob/master/python/sentencepiece_python_module_example.ipynb

https://mlexplained.com/2019/11/06/a-deep-dive-into-the-wonderful-world-of-preprocessing-in-nlp/

### - Farm (Framework for Adapting Representation Models)

https://github.com/deepset-ai/FARM

### - CNN + Text Classification

https://www.aclweb.org/anthology/D14-1181.pdf

https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf

https://reniew.github.io/26/

https://heung-bae-lee.github.io/2020/02/01/NLP_05/

https://buomsoo-kim.github.io/keras/2018/05/16/Easy-deep-learning-with-Keras-12.md/

https://buomsoo-kim.github.io/keras/2018/05/23/Easy-deep-learning-with-Keras-13.md/

### - Documents Clustering For Kmeans

https://lovit.github.io/nlp/machine%20learning/2018/03/19/kmeans_initializer/

https://github.com/lovit/clustering4docs/blob/master/tutorial.ipynb

### - NLP Tokenizers

https://blog.floydhub.com/tokenization-nlp/

### - 정답 유형을 분류하는 딥러닝 기술

https://tech.kakaoenterprise.com/64?fbclid=IwAR2cE9axZjIup_0EzOLBNhq3llVF--g6oHW67SxW6OqEivArIoJA6fPDMJ4

### - GPT-3

https://blog.pingpong.us/gpt3-review/?fbclid=IwAR3qKW1Ev_BRxV97ii9d0sK8tSwpQYGZLEKhDvStrTKMo9dbABFB1ouwBUo

### - Lime & Shap Algorithm

https://towardsdatascience.com/explain-nlp-models-with-lime-shap-5c5a9f84d59b

https://marcotcr.github.io/lime/tutorials/Lime%20-%20multiclass.html

https://www.youtube.com/watch?v=K4nU7yXy7R8&list=PLRnpTeT6IGjIfxyQOjje9T_fKgeFaYEwc&index=92&t=0s

### - A Convolutional Attention Model for Text Classification

https://www.researchgate.net/profile/Ruifeng_Xu2/publication/322247966_A_Convolutional_Attention_Model_for_Text_Classification/links/5b03e6c0aca2720ba09960d2/A-Convolutional-Attention-Model-for-Text-Classification.pdf

https://blog.naver.com/PostView.nhn?blogId=hist0134&logNo=221386940063&parentCategoryNo=&categoryNo=21&viewDate=&isShowPopularPosts=true&from=search


### - BLEU Score

https://donghwa-kim.github.io/BLEU.html

### - Attention For Text Classification

https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794

### - Vdcnn Text Classification

https://arxiv.org/pdf/1606.01781.pdf

### - FROM Pre-trained Word Embeddings TO Pre-trained Language Models — Focus on BERT

https://towardsdatascience.com/from-pre-trained-word-embeddings-to-pre-trained-language-models-focus-on-bert-343815627598

### - 은닉마르코프모델을 이용한 정보추출

https://bi.snu.ac.kr/Publications/Theses/EomJH_MS01.pdf

### - 클린봇 2.0: 문맥을 이해하는 악성 댓글(단문) 탐지 AI

https://d2.naver.com/helloworld/7753273

### -  BERT-based Lexical Substitution

https://www.aclweb.org/anthology/P19-1328.pdf


### - 모두의 말뭉치

https://corpus.korean.go.kr/#down

### - 지프의 법칙

https://ko.wikipedia.org/wiki/%EC%A7%80%ED%94%84%EC%9D%98_%EB%B2%95%EC%B9%99
